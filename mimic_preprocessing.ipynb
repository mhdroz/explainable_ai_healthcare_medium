{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee81747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = \"ADD YOUR PATH\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mimic_tables():\n",
    "    \"\"\"Load the essential MIMIC-IV tables for readmission prediction\"\"\"\n",
    "    \n",
    "    print(\"Loading MIMIC-IV tables...\")\n",
    "    \n",
    "    # Core tables we need\n",
    "    tables = {\n",
    "        'admissions': f'{DATA_PATH}/hosp/admissions.csv',\n",
    "        'patients': f'{DATA_PATH}/hosp/patients.csv',\n",
    "        'diagnoses_icd': f'{DATA_PATH}/hosp/diagnoses_icd.csv',\n",
    "        'labevents': f'{DATA_PATH}/hosp/labevents.csv',\n",
    "    }\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    for table_name, file_path in tables.items():\n",
    "        try:\n",
    "            print(f\"Loading {table_name}...\")\n",
    "            data[table_name] = pd.read_csv(file_path)\n",
    "            print(f\"Shape: {data[table_name].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Could not find {file_path}\")\n",
    "            data[table_name] = None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05102e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_data = load_mimic_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_admissions_data(admissions_df):\n",
    "    \"\"\"Preprocess the admissions table to add length of stay\"\"\"\n",
    "    \n",
    "    print(f\"Total admissions: {len(admissions_df):,}\")\n",
    "    print(f\"Unique patients: {admissions_df['subject_id'].nunique():,}\")\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    admissions_df['admittime'] = pd.to_datetime(admissions_df['admittime'])\n",
    "    admissions_df['dischtime'] = pd.to_datetime(admissions_df['dischtime'])\n",
    "    \n",
    "    # Calculate length of stay\n",
    "    admissions_df['los_days'] = (admissions_df['dischtime'] - admissions_df['admittime']).dt.days\n",
    "    \n",
    "    print(f\"Average length of stay: {admissions_df['los_days'].mean():.1f} days\")\n",
    "    print(f\"Median length of stay: {admissions_df['los_days'].median():.1f} days\")\n",
    "    \n",
    "    # Show admission types\n",
    "    print(\"\\nAdmission types:\")\n",
    "    print(admissions_df['admission_type'].value_counts())\n",
    "    \n",
    "    return admissions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e315b8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total admissions: 546,028\n",
      "Unique patients: 223,452\n",
      "Average length of stay: 4.2 days\n",
      "Median length of stay: 2.0 days\n",
      "\n",
      "Admission types:\n",
      "admission_type\n",
      "EW EMER.                       177459\n",
      "EU OBSERVATION                 119456\n",
      "OBSERVATION ADMIT               84437\n",
      "URGENT                          54929\n",
      "SURGICAL SAME DAY ADMISSION     42898\n",
      "DIRECT OBSERVATION              24551\n",
      "DIRECT EMER.                    21973\n",
      "ELECTIVE                        13130\n",
      "AMBULATORY OBSERVATION           7195\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "admissions = preprocess_admissions_data(mimic_data['admissions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tutorial_subset(admissions_df, n_patients=100000, random_state=42):\n",
    "    \"\"\"\n",
    "    Create a representative subset for tutorial purposes\n",
    "    \n",
    "    Parameters:\n",
    "    - admissions_df: Full admissions dataframe\n",
    "    - n_patients: Number of patients to sample (default: 100k)\n",
    "    - random_state: For reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get unique patients\n",
    "    all_patients = admissions_df['subject_id'].unique()\n",
    "    print(f\"Total patients available: {len(all_patients):,}\")\n",
    "    \n",
    "    # Sample patients (not admissions) to maintain patient history\n",
    "    np.random.seed(random_state)\n",
    "    selected_patients = np.random.choice(\n",
    "        all_patients, \n",
    "        size=min(n_patients, len(all_patients)), \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Filter admissions to selected patients\n",
    "    subset_admissions = admissions_df[\n",
    "        admissions_df['subject_id'].isin(selected_patients)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Selected patients: {len(selected_patients):,}\")\n",
    "    print(f\"Selected admissions: {len(subset_admissions):,}\")\n",
    "    print(f\"Avg admissions per patient: {len(subset_admissions)/len(selected_patients):.1f}\")\n",
    "    \n",
    "    # Check readmission rate is preserved\n",
    "    if 'readmitted' in subset_admissions.columns:\n",
    "        readmit_rate = subset_admissions['readmitted'].mean()\n",
    "        print(f\"Readmission rate in subset: {readmit_rate:.2%}\")\n",
    "    \n",
    "    return subset_admissions, selected_patients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset for tutorial\n",
    "admissions_subset, selected_patients = create_tutorial_subset(\n",
    "    admissions, \n",
    "    n_patients=100000,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readmission_target(admissions_df, readmission_days=30):\n",
    "    \"\"\"\n",
    "    Create binary target variable for readmission within specified days\n",
    "    \n",
    "    Parameters:\n",
    "    - admissions_df: DataFrame with admission records\n",
    "    - readmission_days: Number of days to define readmission (default: 30)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Creating {readmission_days}-day readmission target...\")\n",
    "    \n",
    "    # Sort by patient and admission time\n",
    "    admissions_sorted = admissions_df.sort_values(['subject_id', 'admittime']).copy()\n",
    "    \n",
    "    # For each admission, check if there's another admission within readmission_days\n",
    "    admissions_sorted['readmitted'] = 0\n",
    "    \n",
    "    # Group by patient to find readmissions\n",
    "    for subject_id, group in admissions_sorted.groupby('subject_id'):\n",
    "        if len(group) > 1:  # Patient has multiple admissions\n",
    "            group_sorted = group.sort_values('admittime')\n",
    "            \n",
    "            for i in range(len(group_sorted) - 1):\n",
    "                current_discharge = group_sorted.iloc[i]['dischtime']\n",
    "                next_admission = group_sorted.iloc[i + 1]['admittime']\n",
    "                \n",
    "                # Calculate days between discharge and next admission\n",
    "                if pd.notna(current_discharge) and pd.notna(next_admission):\n",
    "                    days_diff = (next_admission - current_discharge).days\n",
    "                    \n",
    "                    if 0 <= days_diff <= readmission_days:\n",
    "                        # Mark current admission as having readmission\n",
    "                        hadm_id = group_sorted.iloc[i]['hadm_id']\n",
    "                        admissions_sorted.loc[\n",
    "                            admissions_sorted['hadm_id'] == hadm_id, 'readmitted'\n",
    "                        ] = 1\n",
    "    \n",
    "    readmission_rate = admissions_sorted['readmitted'].mean()\n",
    "    print(f\"{readmission_days}-day readmission rate: {readmission_rate:.2%}\")\n",
    "    print(f\"Readmissions: {admissions_sorted['readmitted'].sum():,}\")\n",
    "    print(f\"No readmissions: {(admissions_sorted['readmitted'] == 0).sum():,}\")\n",
    "    \n",
    "    return admissions_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82abb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create readmission target\n",
    "admissions_with_target = create_readmission_target(admissions_subset, readmission_days=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357802a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_related_tables(mimic_data, selected_patients):\n",
    "    \"\"\"Filter all MIMIC tables to selected patients\"\"\"\n",
    "    \n",
    "    print(\"Filtering related tables to selected patients...\")\n",
    "    \n",
    "    filtered_data = {}\n",
    "    \n",
    "    for table_name, df in mimic_data.items():\n",
    "        if df is not None and 'subject_id' in df.columns:\n",
    "            filtered_df = df[df['subject_id'].isin(selected_patients)].copy()\n",
    "            filtered_data[table_name] = filtered_df\n",
    "            \n",
    "            reduction = (1 - len(filtered_df)/len(df)) * 100\n",
    "            print(f\"{table_name}: {len(df):,} --> {len(filtered_df):,} ({reduction:.1f}% reduction)\")\n",
    "        else:\n",
    "            filtered_data[table_name] = df\n",
    "    \n",
    "    return filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317adec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all tables\n",
    "mimic_data_subset = filter_related_tables(mimic_data, selected_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_demographics(patients_df, admissions_df):\n",
    "    \"\"\"Extract and process patient demographic features\"\"\"\n",
    "    \n",
    "    if patients_df is None or admissions_df is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Processing demographics...\")\n",
    "\n",
    "    \n",
    "    # Merge with admissions to calculate age at admission\n",
    "    demo_features = admissions_df.merge(\n",
    "        patients_df[['subject_id', 'gender', 'anchor_age']], \n",
    "        on='subject_id', \n",
    "        how='left'\n",
    "    )\n",
    "    # age at admission is already available in MIMIC-IV\n",
    "    demo_features['age_at_admission'] = demo_features['anchor_age']\n",
    "    \n",
    "    # Create age groups\n",
    "    demo_features['age_group'] = pd.cut(\n",
    "        demo_features['age_at_admission'], \n",
    "        bins=[0, 18, 35, 50, 65, 80, 100], \n",
    "        labels=['<18', '18-35', '35-50', '50-65', '65-80', '80+']\n",
    "    )\n",
    "    \n",
    "    # Gender encoding (F=0, M=1)\n",
    "    demo_features['gender_male'] = (demo_features['gender'] == 'M').astype(int)\n",
    "    \n",
    "    print(f\"Age statistics:\")\n",
    "    print(f\"Mean age: {demo_features['age_at_admission'].mean():.1f} years\")\n",
    "    print(f\"Median age: {demo_features['age_at_admission'].median():.1f} years\")\n",
    "    \n",
    "    print(f\"Gender distribution:\")\n",
    "    print(demo_features['gender'].value_counts())\n",
    "    \n",
    "    return demo_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265375c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process demographics\n",
    "demographics = process_demographics(mimic_data_subset['patients'], admissions_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icdmappings import Mapper\n",
    "\n",
    "def process_diagnoses(diagnoses_df, top_n=50):\n",
    "    \"\"\"\n",
    "    Extract top diagnosis categories as features, mapping ICD-9 to ICD-10\n",
    "    \n",
    "    Parameters:\n",
    "    - diagnoses_df: DataFrame with ICD diagnosis codes\n",
    "    - top_n: Number of top diagnoses to include as features\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing diagnoses with ICD-9 to ICD-10 mapping...\")\n",
    "\n",
    "    icd_mapper = Mapper()\n",
    "    \n",
    "    # Create working copy\n",
    "    diagnoses_mapped = diagnoses_df.copy()\n",
    "    \n",
    "    # Check ICD version distribution\n",
    "    icd9_count = diagnoses_mapped[diagnoses_mapped['icd_version'] == 9].shape[0]\n",
    "    icd10_count = diagnoses_mapped[diagnoses_mapped['icd_version'] == 10].shape[0]\n",
    "    \n",
    "    print(f\"  ✓ Original distribution: ICD-9: {icd9_count:,}, ICD-10: {icd10_count:,}\")\n",
    "    \n",
    "    # Map ICD-9 codes to ICD-10 where possible\n",
    "    mapped_count = 0\n",
    "    for idx, row in diagnoses_mapped.iterrows():\n",
    "        if row['icd_version'] == 9:\n",
    "            diagnoses_mapped.at[idx, 'icd_code'] = icd_mapper.map(row['icd_code'], source='icd9', target='icd10')\n",
    "            diagnoses_mapped.at[idx, 'icd_version'] = 10\n",
    "            mapped_count += 1\n",
    "    \n",
    "    print(f\"  ✓ Mapped {mapped_count:,} ICD-9 codes to ICD-10\")\n",
    "    \n",
    "    # For unmapped ICD-9 codes, we'll keep them but prefix with \"ICD9_\"\n",
    "    # This way we don't lose information but can distinguish versions\n",
    "    # This should not happen with this library\n",
    "    unmapped_mask = diagnoses_mapped['icd_version'] == 9\n",
    "    diagnoses_mapped.loc[unmapped_mask, 'icd_code'] = 'ICD9_' + diagnoses_mapped.loc[unmapped_mask, 'icd_code']\n",
    "    \n",
    "    unmapped_count = unmapped_mask.sum()\n",
    "    print(f\"Kept {unmapped_count:,} unmapped ICD-9 codes with 'ICD9_' prefix\")\n",
    "    \n",
    "    # Now get top diagnoses from the processed codes\n",
    "    top_diagnoses = diagnoses_mapped['icd_code'].value_counts().head(top_n).index\n",
    "    \n",
    "    print(f\"Selected top {top_n} diagnoses after mapping\")\n",
    "    \n",
    "    # Create binary features for each top diagnosis\n",
    "    diagnosis_features = []\n",
    "    \n",
    "    for hadm_id, group in diagnoses_mapped.groupby('hadm_id'):\n",
    "        # Create a row for this admission\n",
    "        row = {'hadm_id': hadm_id}\n",
    "        \n",
    "        admission_diagnoses = set(group['icd_code'].tolist())\n",
    "        \n",
    "        for diagnosis in top_diagnoses:\n",
    "            # Clean column name for better readability\n",
    "            col_name = f'diag_{str(diagnosis).replace(\".\", \"_\")}'\n",
    "            row[col_name] = int(diagnosis in admission_diagnoses)\n",
    "        \n",
    "        diagnosis_features.append(row)\n",
    "    \n",
    "    diagnosis_df = pd.DataFrame(diagnosis_features)\n",
    "    \n",
    "    print(f\"Created {len(top_diagnoses)} diagnosis features\")\n",
    "    print(f\"Coverage: {len(diagnosis_df)} admissions\")\n",
    "    \n",
    "    # Show most common diagnoses after mapping\n",
    "    print(f\"Top 5 diagnoses after ICD mapping:\")\n",
    "    for i, diag in enumerate(top_diagnoses[:5]):\n",
    "        count = diagnoses_mapped[diagnoses_mapped['icd_code'] == diag].shape[0]\n",
    "        diag_type = \"ICD-10\" if not diag.startswith('ICD9_') else \"ICD-9\"\n",
    "        print(f\"    {i+1}. {diag} ({diag_type}): {count:,} cases\")\n",
    "    \n",
    "    return diagnosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_features = process_diagnoses(mimic_data_subset['diagnoses_icd'], top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ece1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lab_values(labevents_df, admissions_df, important_labs=None):\n",
    "    \"\"\"\n",
    "    Extract summary statistics for important lab values\n",
    "    \n",
    "    Parameters:\n",
    "    - labevents_df: DataFrame with lab events\n",
    "    - admissions_df: DataFrame with admissions\n",
    "    - important_labs: List of important lab itemids\n",
    "    \"\"\"\n",
    "\n",
    "    # Define important lab tests (common ones for readmission prediction)\n",
    "    if important_labs is None:\n",
    "        important_labs = {\n",
    "            50868: 'aniongap',      # Anion Gap\n",
    "            50882: 'bicarbonate',   # Bicarbonate\n",
    "            50893: 'calcium',       # Calcium\n",
    "            50902: 'chloride',      # Chloride\n",
    "            50912: 'creatinine',    # Creatinine\n",
    "            50931: 'glucose',       # Glucose\n",
    "            50960: 'magnesium',     # Magnesium\n",
    "            50970: 'phosphate',     # Phosphate\n",
    "            50971: 'potassium',     # Potassium\n",
    "            50983: 'sodium',        # Sodium\n",
    "            51006: 'urea',          # Urea Nitrogen\n",
    "            51221: 'hematocrit',    # Hematocrit\n",
    "            51222: 'hemoglobin',    # Hemoglobin\n",
    "            51265: 'platelet',      # Platelet Count\n",
    "            51301: 'wbc'            # White Blood Cells\n",
    "        }\n",
    "    \n",
    "    print(f\"Processing {len(important_labs)} important lab values...\")\n",
    "    \n",
    "    # Filter to important labs only\n",
    "    important_lab_data = labevents_df[\n",
    "        labevents_df['itemid'].isin(important_labs.keys())\n",
    "    ].copy()\n",
    "    \n",
    "    # Convert lab values to numeric (handle text values)\n",
    "    important_lab_data['valuenum'] = pd.to_numeric(\n",
    "        important_lab_data['valuenum'], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Remove extreme outliers (99.5th percentile filter)\n",
    "    for itemid in important_labs.keys():\n",
    "        lab_data = important_lab_data[important_lab_data['itemid'] == itemid]\n",
    "        if len(lab_data) > 0:\n",
    "            upper_limit = lab_data['valuenum'].quantile(0.995)\n",
    "            lower_limit = lab_data['valuenum'].quantile(0.005)\n",
    "            mask = (\n",
    "                (important_lab_data['itemid'] == itemid) & \n",
    "                (important_lab_data['valuenum'] > upper_limit)\n",
    "            ) | (\n",
    "                (important_lab_data['itemid'] == itemid) & \n",
    "                (important_lab_data['valuenum'] < lower_limit)\n",
    "            )\n",
    "            important_lab_data.loc[mask, 'valuenum'] = np.nan\n",
    "    \n",
    "    # Aggregate lab values by admission\n",
    "    lab_features = []\n",
    "    \n",
    "    for hadm_id in admissions_df['hadm_id'].unique():\n",
    "        admission_labs = important_lab_data[\n",
    "            important_lab_data['hadm_id'] == hadm_id\n",
    "        ]\n",
    "        \n",
    "        row = {'hadm_id': hadm_id}\n",
    "        \n",
    "        for itemid, lab_name in important_labs.items():\n",
    "            lab_values = admission_labs[\n",
    "                admission_labs['itemid'] == itemid\n",
    "            ]['valuenum'].dropna()\n",
    "            \n",
    "            if len(lab_values) > 0:\n",
    "                # Create summary statistics\n",
    "                row[f'{lab_name}_mean'] = lab_values.mean()\n",
    "                row[f'{lab_name}_min'] = lab_values.min()\n",
    "                row[f'{lab_name}_max'] = lab_values.max()\n",
    "                row[f'{lab_name}_count'] = len(lab_values)\n",
    "            else:\n",
    "                # Missing values\n",
    "                row[f'{lab_name}_mean'] = np.nan\n",
    "                row[f'{lab_name}_min'] = np.nan\n",
    "                row[f'{lab_name}_max'] = np.nan\n",
    "                row[f'{lab_name}_count'] = 0\n",
    "        \n",
    "        lab_features.append(row)\n",
    "    \n",
    "    lab_df = pd.DataFrame(lab_features)\n",
    "    \n",
    "    print(f\"Created lab features for {len(lab_df)} admissions\")\n",
    "    print(f\"Lab features per admission: {len(important_labs) * 4}\")\n",
    "    \n",
    "    # Show data availability\n",
    "    for itemid, lab_name in list(important_labs.items())[:5]:\n",
    "        availability = (lab_df[f'{lab_name}_count'] > 0).mean()\n",
    "        print(f\"    {lab_name}: {availability:.1%} of admissions\")\n",
    "    \n",
    "    return lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_features = process_lab_values(\n",
    "    mimic_data_subset['labevents'], \n",
    "    admissions_with_target,\n",
    "    important_labs=None\n",
    ")\n",
    "# This takes about 60min for 100,000 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in case we need to restart because it takes a long time to process\n",
    "lab_features = pd.read_parquet('lab_features.parquet')\n",
    "lab_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(demographics_df, diagnosis_df, lab_df):\n",
    "    \"\"\"Combine all processed features into final dataset\"\"\"\n",
    "    \n",
    "    # Start with demographics (includes readmission target)\n",
    "    final_df = demographics_df.copy()\n",
    "    \n",
    "    # Add diagnosis features\n",
    "    final_df = final_df.merge(diagnosis_df, on='hadm_id', how='left')\n",
    "        \n",
    "    # Fill missing diagnosis features with 0 (patient didn't have that diagnosis)\n",
    "    diag_cols = [col for col in diagnosis_df.columns if col.startswith('diag_')]\n",
    "    final_df[diag_cols] = final_df[diag_cols].fillna(0)\n",
    "    \n",
    "    # Add lab features\n",
    "    final_df = final_df.merge(lab_df, on='hadm_id', how='left')\n",
    "    \n",
    "    # Select final feature columns\n",
    "    feature_columns = [\n",
    "        'hadm_id', 'subject_id', 'readmitted',  # IDs and target\n",
    "        'age_at_admission', 'gender_male', 'los_days',  # Demographics\n",
    "        'admission_type', 'insurance'  # Admission details\n",
    "    ]\n",
    "    \n",
    "    # Add diagnosis features\n",
    "    feature_columns.extend([col for col in final_df.columns if col.startswith('diag_')])\n",
    "    \n",
    "    # Add lab features\n",
    "    feature_columns.extend([col for col in final_df.columns if col.endswith('_mean')])\n",
    "    \n",
    "    # Filter to available columns\n",
    "    available_columns = [col for col in feature_columns if col in final_df.columns]\n",
    "    final_df = final_df[available_columns]\n",
    "    \n",
    "    print(f\"Final dataset shape: {final_df.shape}\")\n",
    "    print(f\"Total features: {len(available_columns) - 3}\")  # Minus IDs and target\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70766306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all features...\n",
      "  ✓ Adding diagnosis features...\n",
      "  ✓ Adding lab features...\n",
      "  ✓ Final dataset shape: (244240, 53)\n",
      "  ✓ Total features: 50\n"
     ]
    }
   ],
   "source": [
    "final_dataset = combine_features(demographics, diagnosis_features, lab_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4f60784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (244240, 53)\n",
      "Readmission rate: 20.38%\n",
      "\n",
      "Features:\n",
      "\n",
      "Demographics: 3 features\n",
      "Diagnosis: 30 features\n",
      "Lab Values: 15 features\n",
      "\n",
      "Missing values analysis:\n",
      "\n",
      "Features with >20% missing values:\n",
      "aniongap_mean: 25.4% missing\n",
      "bicarbonate_mean: 25.4% missing\n",
      "calcium_mean: 31.7% missing\n",
      "chloride_mean: 24.9% missing\n",
      "creatinine_mean: 23.9% missing\n",
      "glucose_mean: 25.5% missing\n",
      "magnesium_mean: 30.5% missing\n",
      "phosphate_mean: 32.2% missing\n",
      "potassium_mean: 24.5% missing\n",
      "sodium_mean: 24.8% missing\n",
      "urea_mean: 24.5% missing\n",
      "hematocrit_mean: 21.2% missing\n",
      "hemoglobin_mean: 22.7% missing\n",
      "platelet_mean: 22.4% missing\n",
      "wbc_mean: 22.8% missing\n",
      "\n",
      "Saved processed dataset to: mimic_readmission_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Final dataset statistics\n",
    "print(f\"Final dataset shape: {final_dataset.shape}\")\n",
    "print(f\"Readmission rate: {final_dataset['readmitted'].mean():.2%}\")\n",
    "    \n",
    "# Show feature categories\n",
    "feature_types = {\n",
    "        'Demographics': ['age_at_admission', 'gender_male', 'los_days'],\n",
    "        'Diagnosis': [col for col in final_dataset.columns if col.startswith('diag_')],\n",
    "        'Lab Values': [col for col in final_dataset.columns if col.endswith('_mean')]\n",
    "    }\n",
    "print(\"\\nFeatures:\\n\")\n",
    "for category, features in feature_types.items():\n",
    "        available_features = [f for f in features if f in final_dataset.columns]\n",
    "        print(f\"{category}: {len(available_features)} features\")\n",
    "    \n",
    "# Check for missing values\n",
    "missing_pct = (final_dataset.isnull().sum() / len(final_dataset)) * 100\n",
    "high_missing = missing_pct[missing_pct > 20]\n",
    "    \n",
    "print(\"\\nMissing values analysis:\\n\")\n",
    "if len(high_missing) > 0:\n",
    "        print(f\"Features with >20% missing values:\")\n",
    "        for feature, pct in high_missing.items():\n",
    "            print(f\"{feature}: {pct:.1f}% missing\")\n",
    "    \n",
    "    # Save processed dataset\n",
    "output_file = 'mimic_readmission_features.csv'\n",
    "final_dataset.to_csv(output_file, index=False)\n",
    "print(f\"\\nSaved processed dataset to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6774e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_medium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
